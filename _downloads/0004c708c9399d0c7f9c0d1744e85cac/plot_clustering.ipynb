{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Clustering\n\nThis tutorial aims to explain and visualize the use of the clustering\nalgorithms implemented in the package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nClustering is a form of unsupervised learning where data samples are grouped\nin clusters by using some metric of similarity between the samples.\n\nIn this package, the two algorithms implemented are distance-based. This\nmeans that the similarity measure being used to group the samples is\nthe Euclidean distance or L2-norm.\n\nThe distances in the algorithms can be computed classically or estimated\nwith a quantum subroutine. The quantum estimation has a time complexity of\n$O(\\log N)$ compared to $O(N)$ for its classical counterpart,\nwhich produces an exponential speed-up. For more information in the\nmathematical reasoning behind the estimation subroutine, refer to\n:meth:`skqlearn.utils.distance_estimation`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to represent the cluster assignments, a utility function is defined\nthat plots the data assignments as well as the center of each cluster.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skqlearn.utils import JobHandler\nfrom skqlearn.ml.clustering import *\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom qiskit.providers.aer import AerSimulator\nfrom sklearn.datasets import make_blobs\n\n\ndef plot_cluster(axis, x, labels, centers):\n    legend = []\n\n    axis.set(xlabel=r'$X_1$', ylabel=r'$X_2$')\n    axis.set_aspect('auto', 'box')\n\n    for y in np.unique(labels):\n        members = labels == y\n        axis.scatter(x[members, 0], x[members, 1], label='_nolegend_')\n        axis.scatter(centers[y, 0], centers[y, 1], s=[100], marker='X')\n        legend.append(f'Centroid {y}')\n\n\n    axis.legend(legend)\n\n\ndef plot_comparison(x, clf_classic, clf_quantum, title):\n    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n    fig.suptitle(title)\n    ax1.set_title('Classic Distance Calculation')\n    ax2.set_title('Quantum Distance Estimation')\n    plt.subplots_adjust(left=0.15, bottom=0.1, right=0.95, top=0.85, wspace=0.12)\n\n    plot_cluster(ax1, x, clf_classic.labels, clf_classic.cluster_centers)\n    plot_cluster(ax2, x, clf_quantum.labels, clf_quantum.cluster_centers)\n\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the tutorial will also test the quantum distance estimation\nalgorithm, the quantum backend must be configured.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "JobHandler().configure(backend=AerSimulator(), shots=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, random data is generated centered around two points. For a first test,\nthe data generated is clearly separated into two clusters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\ncenters = np.array([[0, 0], [0, 1]])\nx, labels = make_blobs(n_samples=20, centers=centers, cluster_std=0.1)\n\nplot_cluster(plt.gca(), x, labels, centers)\nplt.title('Generated data for two blobs')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KMeans\n\nThe implementation of the KMeans algorithm is based on an iterative\nrefinement technique. The cluster centers are initially chosen at random\nbetween the training data. After that, the algorithm assigns each data\nsample to the closest centroid (cluster center) and recalculates the centroid\nas the mean of all sample data assigned to it. This process is repeated until\nthere is no change of assignments between two iterations or the iteration\nlimit is reached.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step will be to train the algorithm with the data samples. During\nthe training, the values for the centroids are stored in the object, as well\nas the final labels/assignments for the data samples. This allows us to\nsee how the algorithm has decided to cluster the data samples. The distance\ncalculation method can be provided in the constructor of the class, in order\nto choose between the classic and quantum calculations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "k_means_classic = KMeans(n_clusters=len(centers),\n                         max_iterations=20,\n                         random_state=0,\n                         distance_calculation_method='classic')\nk_means_classic.fit(x)\n\nk_means_quantum = KMeans(n_clusters=len(centers),\n                         max_iterations=20,\n                         random_state=0,\n                         distance_calculation_method='quantum')\nk_means_quantum.fit(x)\n\nplot_comparison(x, k_means_classic, k_means_quantum,\n                'KMeans Clustering on two blobs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The trained estimators can then be used to assign new data to the current\nclusters by using the `predict` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_data = np.array([[-1, 0], [0, 2]])\nprint(k_means_classic.predict(new_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KMedians\n\nKMedians follows the same structure as KMeans. The only difference between\nthe two algorithms is how the centroids are updated after every iteration.\nIn KMedians, the centroid is calculated as the median of all data samples\nassigned to it, with the median being defined as the sample that minimizes\nthe distance to all other samples:\n\n\\begin{align}arg\\,min_{\\boldsymbol{x}_j}\\sum_{i=1}^m||\\boldsymbol{x}_i -\n   \\boldsymbol{x}_j||_{2}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "k_medians_classic = KMedians(n_clusters=len(centers),\n                             max_iterations=20,\n                             random_state=0,\n                             distance_calculation_method='classic')\nk_medians_classic.fit(x)\n\nk_medians_quantum = KMedians(n_clusters=len(centers),\n                             max_iterations=20,\n                             random_state=0,\n                             distance_calculation_method='quantum')\nk_medians_quantum.fit(x)\n\nplot_comparison(x, k_medians_classic, k_medians_quantum,\n                'KMedians Clustering on two blobs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also interesting to see the decisions made by the algorithms with\nless straight forward data. For testing purposes, only one\ncluster of data is generated in order to show how the algorithms behave.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "centers_2 = np.array([[0, 0]])\nx_2, labels_2 = make_blobs(n_samples=20, centers=centers_2, cluster_std=0.05)\n\nplot_cluster(plt.gca(), x_2, labels_2, centers_2)\nplt.title('Generated Data for one blob')\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "k_means_classic_2 = KMeans(n_clusters=2,\n                           max_iterations=40,\n                           random_state=0,\n                           distance_calculation_method='classic')\nk_means_classic_2.fit(x_2)\n\nk_means_quantum_2 = KMeans(n_clusters=2,\n                           max_iterations=40,\n                           random_state=0,\n                           distance_calculation_method='quantum')\nk_means_quantum_2.fit(x_2)\n\nplot_comparison(x_2, k_means_classic_2, k_means_quantum_2,\n                'KMeans Clustering on one blob')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "k_medians_classic_2 = KMedians(n_clusters=2,\n                               max_iterations=40,\n                               random_state=0,\n                               distance_calculation_method='classic')\nk_medians_classic_2.fit(x_2)\n\nk_medians_quantum_2 = KMedians(n_clusters=2,\n                               max_iterations=40,\n                               random_state=0,\n                               distance_calculation_method='quantum')\nk_medians_quantum_2.fit(x_2)\n\nplot_comparison(x_2, k_medians_classic_2, k_medians_quantum_2,\n                'KMedians Clustering on one blob')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}