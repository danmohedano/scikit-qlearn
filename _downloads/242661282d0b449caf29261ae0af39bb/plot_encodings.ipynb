{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Data Encodings\n\nThis tutorial aims to explain and visualize the different data encoding methods\nimplemented in the package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nMachine Learning algorithms rely on sample data in order to train and learn.\nWhen trying to enhance these algorithms with quantum subroutines, the first\nissue one can encounter is how to translate the classical sample data into\na format that can be understood by a quantum machine.\n\nWhile classical computers' most basic unit of information is the bit, quantum\nmachines' is the qubit. Classical bits can only hold/represent one of two\nvalues, 0 or 1, as all information can be represented with combinations of\nenough of these binary values. Qubits, on the other hand, can be thought of\nas a 2-state system such as a spin-half . The state of these systems can then\nbe described with quantum states. A system is said to have *n* qubits if it\nhas a Hilbert space of $N=2^n$ dimensions and, thus, has $2^n$\nmutually orthogonal quantum states, denoted as basis states\n:cite:`steane1998quantum`. The main difference with classical mechanics is\nthat the system, by superposition, can be in a linear combination of these\nbasis states, represented as unit vectors of the form\n$x_1=[1,0,...,0]^T$.\n\nTherefore, a generic state $\\left|\\psi\\right>$ can be defined as a\ncombination of the basis states\n$\\{\\left|x_1\\right>,...,\\left|x_N\\right>\\}$.\n\n\\begin{align}\\left|\\psi\\right> = c_1\\left|x_1\\right>+...+c_N\\left|x_N\\right>\\end{align}\n\nThe weights of the linear combination, $c_i\\in\\mathbb{C}$, are called\ncomplex amplitudes or probability amplitudes. The norm square of these\ndefines the probability of the system being found in each of the basis states\nafter measurement. Because of this, the probability amplitudes need to be\nnormalized in order to define a proper quantum state.\nA quantum state can thus be represented as its amplitude\nvector $[c_1,...,c_N]^T$.\n\nThe following encoding methods describe how to encode the sample data into\nan amplitude vector in order to represent a quantum state. These methods\ncan be defined as feature maps of the form:\n\n\\begin{align}\\phi: \\mathcal{X} \\rightarrow \\mathcal{F}\\end{align}\n\nWhere the input $x$ is mapped from the input space into the feature\nspace.\n\nIn order to visually represent the transformations, another representation of\nquantum states will be used: the Bloch sphere. This is a geometrical\nrepresentation of a qubit where its quantum state is shown as a point in the\nunit sphere. The antipodal points correspond to the two basis states\n$\\left|0\\right>$ and $\\left|1\\right>$. The translation into\nspherical coordinates is then made by defining the quantum state as:\n\n\\begin{align}\\left|\\psi\\right> = c_0\\left|0\\right>+c_1\\left|1\\right> = \\cos{\n   \\frac{\\theta}{2}}\\left|0\\right>+e^{i\\phi}\\sin{\\frac{\\theta}{2}}\n   \\left|1\\right>\\end{align}\n\n## Basis Encoding\n\nIn basis encoding, each classical bit of a value is mapped into a single\nqubit, defining the encoding feature map as:\n\n\\begin{align}\\phi:i\\rightarrow \\left|i\\right>\\end{align}\n\nThis means that a value $x$ would need $\\lceil\\log_2 x\\rceil$\nqubits in order to be mapped.\n\nThe value $0$ would therefore be mapped to the state\n$\\left|0\\right>$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skqlearn.encoding import *\nimport matplotlib.pyplot as plt\nfrom qiskit.quantum_info import Statevector\nimport numpy as np\n\ndata = 0\nstate = Statevector(BasisEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A value like $5$ would need of $3$ qubits for the mapping, each\none representing each bit in the binary representation of the number,\n$101$.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Quantum states defined by the state of each of its qubits, for\n   example $\\left|011\\right>$, are usually represented in little-endian\n   with the first qubit in the left-most position. Qiskit, the SDK used for\n   the visualization of the states, represents the qubits in big-endian.\n   This means that if the state is supposed to be $\\left|011\\right>$,\n   the qubit with state $\\left|0\\right>$ will be shown by Qiskit\n   in the right-most position.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = 5\nstate = Statevector(BasisEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The encoding also permits encoding an entire dataset of binary strings\n$\\mathcal{D}=\\{\\boldsymbol{x}^1,...,\\boldsymbol{x}^m\\}$ together as:\n\n\\begin{align}\\left|\\mathcal{D}\\right> = \\frac{1}{\\sqrt{M}}\\sum_{m=1}^{M}\n   \\left|\\boldsymbol{x}^m\\right>.\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([0, 1, 2, 3])\nstate = Statevector(BasisEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Amplitude Encoding\n\nIn amplitude encoding, each component of the input vector\n$\\boldsymbol{x} \\in \\mathbb{R}^N$ is mapped to an amplitude of the\nquantum state, defining the encoding feature map as:\n\n\\begin{align}\\phi:\\boldsymbol{x}\\rightarrow\\left|\\psi_\\boldsymbol{x}\\right>=\n   \\sum_{i=1}^{N}\\frac{1}{|\\boldsymbol{x}|}x_i\\left|i-1\\right>\\end{align}\n\nIn order to represent a valid quantum state, the amount of amplitudes\nmust be a power of 2, $N=2^n$. If they are not,\nthey can be padded with zeros at the end.\n\nFor this encoding to generate valid quantum states, the input vectors must\nbe normalized. If they are not, the method is responsible for normalizing\nthem. This should be taken into account when planning on using this encoding.\nThe forceful normalization is performed because some subroutines can work\naround the issue.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([1 / np.sqrt(2), 1 / np.sqrt(2)])\nstate = Statevector(AmplitudeEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The input vectors can also be mapped to $d$ copies of the amplitude\nvectors, which can be specially useful when using the kernel defined by the\nencoding feature map.\n\n\\begin{align}\\phi:\\boldsymbol{x}\\rightarrow\\left|\\psi_\\boldsymbol{x}\\right>\n   ^{\\bigotimes d}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([1 / np.sqrt(2), 1 / np.sqrt(2)])\nstate = Statevector(AmplitudeEncoding(degree=2).encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dataset can also be encoded by concatenating all the resulting amplitude\nvectors and normalizing.\n\nIn this case, the first 2D vector is mapped to the first qubit (or last\nin Qiskit's representation) and so on.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [1.0, 0.0]])\nstate = Statevector(AmplitudeEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expanded Amplitude Encoding\n\nThis encoding method tries to solve the normalization problem in regular\nAmplitude Encoding. If non-normalized data is normalized for use on\nAmplitude Encoding, the data will lose one dimension of information. For\nexample, if a 2D point is normalized, it will be mapped into the unit\ncircle, a 1D shape.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "points = np.array([[1, 1],\n                   [2, 2],\n                   [0.5, 3]])\nnormalized_points = points / np.linalg.norm(points, axis=1)[:, None]\nlines = np.array([[[p[0], n[0]], [p[1], n[1]]]\n         for p, n in zip(points, normalized_points)])\n\n# Plot unit circle\nx = np.linspace(0, np.pi / 2, 30)\nplt.plot(np.cos(x), np.sin(x))\n# Plot encodings\nfor i in range(lines.shape[0]):\n    plt.plot(lines[i, 0, :], lines[i, 1, :], '--')\nplt.scatter(points[:, 0], points[:, 1], marker='o')\nplt.scatter(normalized_points[:, 0], normalized_points[:, 1], marker='x')\nplt.xlim([0, 4])\nplt.ylim([0, 4])\nplt.xlabel(r'$X_1$')\nplt.ylabel(r'$X_2$')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By adding an extra component to\n$\\boldsymbol{x}\\in\\mathbb{R}^N$ with a value of $c$,\n$x_{0}=c$, and then normalizing, the information loss is mitigated.\n\n\\begin{align}\\phi:\\boldsymbol{x}\\rightarrow\\left|\\psi_\\boldsymbol{x}\\right>=\n       \\frac{1}{\\sqrt{|\\boldsymbol{x}|^2+c^2}}\\left(c\\left|0\\right> +\n       \\sum_{i=1}^{N}x_i\\left|i\\right>\\right)\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c = 1\npoints = np.array([[1, 1, c],\n                   [2, 2, c],\n                   [0.5, 3, c]])\nnormalized_points = points / np.linalg.norm(points, axis=1)[:, None]\nlines = np.array([[[p[0], n[0]], [p[1], n[1]]]\n         for p, n in zip(points, normalized_points)])\n\n# Plot limits\nplt.plot([0, 1], [1, 1], 'b')\nplt.plot([1, 1], [0, 1], 'b')\n# Plot encodings\nfor i in range(lines.shape[0]):\n    plt.plot(lines[i, 0, :], lines[i, 1, :], '--')\nplt.scatter(points[:, 0], points[:, 1], marker='o')\nplt.scatter(normalized_points[:, 0], normalized_points[:, 1], marker='x')\nplt.xlim([0, 4])\nplt.ylim([0, 4])\nplt.xlabel(r'$X_1$')\nplt.ylabel(r'$X_2$')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown in the figure, now the mapping is injective because of the\nmitigation of information loss. The encoding itself works exactly the same\nas Amplitude Encoding.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([1.0, 1.0, 1.0])\nstate = Statevector(ExpandedAmplitudeEncoding(c=1.0).encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Angle Encoding\n\nIn angle encoding, each component of the input vector\n$\\boldsymbol{x} \\in \\mathbb{R}^N$ is mapped to a qubit, defining the\nencoding feature map as:\n\n\\begin{align}\\phi:\\boldsymbol{x}\\rightarrow\\left|\\psi_\\boldsymbol{x}\\right>=\n   \\bigotimes_{i=1}^{N}\\cos{x_i}\\left|0\\right>+\\sin{x_i}\\left|1\\right>\\end{align}\n\nBecause of the encoding feature map, the resulting quantum state is\ncorrectly normalized and therefore valid, as $\\cos{x}^2+\\sin{x}^2=1$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([0.0, np.pi / 4, np.pi / 2, 3 * np.pi / 4])\nstate = Statevector(AngleEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This encoding method is visualized specially well with the Bloch sphere\nbecause it follows an almost identical definition of how the quantum states\nare represented in the sphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "state.draw('bloch').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QSample Encoding\n\nIn QSample encoding, a discrete probability distribution is mapped into the\namplitude vector of a quantum state, defining the encoding feature map as:\n\n\\begin{align}\\phi:p(x)\\rightarrow \\left|p(x)\\right>=\\sum_{X} \\sqrt{p(x_i)}\n    \\left|x_i\\right>\\end{align}\n\nBecause the amplitudes are defined as $\\alpha_i = \\sqrt{p(x_i)}$,\nthe resulting quantum state is valid:\n$\\sum |\\alpha_i|^2=\\sum p(x_i) = 1$.\n\nThis allows for the measurement of the quantum state to be interpreted as\na sampling of the discrete probability distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.array([0.25, 0.5, 0.25])\nstate = Statevector(QSampleEncoding().encoding(data))\nprint(state.draw('text'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}